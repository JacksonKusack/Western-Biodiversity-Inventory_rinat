---
title: "Western Biodiversity Inventory - Exploration"
author: "Adminon Kusack"
date: "`r Sys.Date()`"
output: html_document
theme: paper
params:
  download:
    label: "Update Data"
    value: FALSE
    input: select
    choices: [TRUE,FALSE]
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "")
```

```{r packages, message=F, warning=F}
library(tidyverse)
library(rinat)
library(jsonlite)
library(ggplot2)

source("C:/Users/Admin/Documents/GitHub/Western-Biodiversity-Inventory_rinat/R/get_inat_user_stats_v2.R") # Modified function to allow for month specific queries
source("C:/Users/Admin/Documents/GitHub/iNatTools/R/iNat_sc.R") # Modified function to fix error in code (forked from iNatTools main)
```


## Observation Data

First we can download observation data for the Biodiversity Inventory at Western. This step can be run each time the code is run, but the processing time/download time is high, so by default it will only download the data if knit with the correct parameters. This saves a dataframe, locally, that contains all of the observations for the project. If the number of observations ever goes above 10,000 the code will need to modified to download subsets separately as the maximum number of downloads using the API is 10,000. In that case, using the **get_inat_obs(...)** function would be easier.  

```{r eval = params$download}
observations <- get_inat_obs(place_id = 142216, month = 1, maxresults = 10000) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 2, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 3, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 4, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 5, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 6, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 7, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 8, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 9, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 10, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 11, maxresults = 10000), observations) 
observations <- rbind(get_inat_obs(place_id = 142216, month = 12, maxresults = 10000), observations) 

write.csv(observations, file = "C:/Users/Admin/Documents/GitHub/Western-Biodiversity-Inventory_rinat/Data/observation.df.csv", row.names = F)
```

```{r echo = F}
observations <- read.csv("C:/Users/Admin/Documents/GitHub/Western-Biodiversity-Inventory_rinat/Data/observation.df.csv")
```

At the time of last download (`r fs::file_info("C:/Users/Admin/Documents/GitHub/Western-Biodiversity-Inventory_rinat/Data/observation.df.csv")$modification_time`), there were `r nrow(observations)` observations. See below for a breakdown of number of observations, by taxonomic grouping:

```{r}
observations %>%
  group_by(iconic_taxon_name) %>%
  summarize(count = n()) %>%
  print.data.frame(row.names = F)
```

## Observer Effort Data

```{r eval = T, fig.width = 6.5, fig.height = 15}
observations.summary <- observations %>%
  mutate('Month' = lubridate::month(lubridate::ymd(observed_on))) %>%
  rename('Taxon' = iconic_taxon_name) %>%
  filter(is.na(Taxon) == F) %>%
  filter(quality_grade == "research") %>%
  group_by(Month, Taxon) %>%
  summarize(Observations = n()) 
  
(p.obs <- ggplot() + 
  geom_point(data = observations.summary, aes(x = Month, y = Observations, col = Taxon)) + 
  geom_line(data = observations.summary, aes(x = Month, y = Observations, col = Taxon)) +
  scale_y_continuous(limits=c(0,NA)) + 
  ylab('Observers (count)') + xlab('Month') + facet_wrap(~Taxon, scales = "free_y", ncol = 1) + 
  theme_linedraw() + theme(panel.grid = element_blank(), axis.text.x = element_text(size = 8)))

png(filename = "C:/Users/Admin/Documents/GitHub/Western-Biodiversity-Inventory_rinat/Figures/Research_grade_observations_xMonth_xTaxon.png",
    res = 300, 
    width = 4, 
    height = 14,
    units = 'in')
p.obs
dev.off()
```


# Most recent species/genus added: top 50

As the iNaturalist webpage doesn't easily summarize which species / taxa was the most recently added to a project, we can use R to sort the observations by date. Obviously, this can also be done though exporting the data directly to a csv file, but R allows us to do this all at once. 

```{r}
observations %>% 
  group_by(scientific_name) %>%
  slice_min(order_by = observed_on) %>%
  arrange(desc(observed_on)) %>%
  dplyr::select(scientific_name, observed_on, user_name) %>%
  data.frame() %>%
  head(50)
```



# Most rare species seen on campus: 

## 2022-2023 Inventory

```{r}
observation.counts <- iNat_sc(project_id = 'biodiversity-inventory-at-western', quality_grade = "research", d1 = "2022-04-01", d2 = "2023-03-31")

rarity.df <- observation.counts %>% 
  arrange(taxon.observations_count) %>%
  dplyr::select(count, taxon.observations_count, taxon.name, taxon.preferred_common_name) %>%
  rename('total.count' = taxon.observations_count) %>%
  rename('common.name' = taxon.preferred_common_name) %>%
  data.frame()

head(rarity.df, 50)
```


## All years

```{r}
observation.counts <- iNat_sc(project_id = 'biodiversity-inventory-at-western', quality_grade = "research")

rarity.df <- observation.counts %>% 
  arrange(taxon.observations_count) %>%
  select(count, taxon.observations_count, taxon.name, taxon.preferred_common_name) %>%
  rename('total.count' = taxon.observations_count) %>%
  rename('common.name' = taxon.preferred_common_name) %>%
  data.frame()

head(rarity.df, 50)
```


```{r echo = F}
rare.1 <- get_inat_obs_id(na.omit(observations$id[observations$scientific_name == rarity.df$taxon.name[1]])[1])
rare.2 <- get_inat_obs_id(na.omit(observations$id[observations$scientific_name == rarity.df$taxon.name[2]])[1])
rare.3 <- get_inat_obs_id(na.omit(observations$id[observations$scientific_name == rarity.df$taxon.name[3]])[1])
rare.4 <- get_inat_obs_id(na.omit(observations$id[observations$scientific_name == rarity.df$taxon.name[4]])[1])
rare.5 <- get_inat_obs_id(na.omit(observations$id[observations$scientific_name == rarity.df$taxon.name[5]])[1])
```

## Rarest

1. `r rarity.df$taxon.name[1]`

<kbd><center><img src="`r rare.1$observation_photos$photo$medium_url[1]`"></center></kbd>

`r rare.1$uri` 

***

2. `r rarity.df$taxon.name[2]`

<kbd><center><img src="`r rare.2$observation_photos$photo$medium_url[1]`"></center></kbd>

`r rare.2$uri` 

***

3. `r rarity.df$taxon.name[3]`

<kbd><center><img src="`r rare.3$observation_photos$photo$medium_url[1]`"></center></kbd>

`r rare.3$uri` 

***

4. `r rarity.df$taxon.name[4]`

<kbd><center><img src="`r rare.4$observation_photos$photo$medium_url[1]`"></center></kbd>

`r rare.4$uri` 

***

5. `r rarity.df$taxon.name[5]`

<kbd><center><img src="`r rare.5$observation_photos$photo$medium_url[1]`"></center></kbd>

`r rare.5$uri` 

# Species accumulation curve: By year

```{r}
table(lubridate::year(lubridate::as_date(observations$observed_on)))

df <- data.frame(rep(0,10),rep(0,10)) 
names(df) <- c('observations','taxa')

for(i in seq_len(nrow(df))) {
  
  temp <- observations %>% 
    mutate(observed_on = lubridate::as_date(observed_on)) %>%
    filter(observed_on >= lubridate::as_date("1988-01-01") & 
             observed_on < lubridate::as_date(paste(2014+i,"-01-01", sep="")))
  df[i,1] <- nrow(temp)
  df[i,2] <- length(unique(temp$taxon_id))
}

print(ggplot(data = df, aes(y = taxa, x = observations)) + 
  geom_point() + 
  stat_smooth(method = "lm", formula = y ~ poly(x,2), se = FALSE, col = "red", fullrange=TRUE) + 
  labs(x = "Number of Observations", y = "Number of Taxa") +
  xlim(0,10000) + ylim(0,3000) +
  theme_classic())
```

Take this figure with a grain of salt, because observer biases come into play here... But last year the curve only just started to plateau near the last few months, indicating that there are plenty of new species to be discovered on campus. Not too surprising though. 

# Most observed species that I'm missing

```{r}
jk.species <- observations %>%
  filter(user_login == 'jacksonkusack') %>%
  select(scientific_name) %>%
  unique()

observation.counts <- iNat_sc(project_id = 'biodiversity-inventory-at-western', quality_grade = "research") %>% 
  arrange(desc(count)) %>%
  filter(taxon.iconic_taxon_name != "Aves") %>%
  dplyr::select(count, taxon.name, taxon.preferred_common_name) %>%
  rename('common.name' = taxon.preferred_common_name) %>%
  data.frame() 

jk.missing <- observation.counts %>%
  subset(!(taxon.name %in% jk.species$scientific_name))

head(jk.missing, 50)
```

# Code for Peter

## Rare observations (<= 10 ON records)

Pull out species with <= 10 observations within Ontario and check for records of those species in the inventory. 

```{r}
#https://inaturalist.ca/projects/biodiversity-of-ontario

ontario.species <- iNat_sc(project_id = 29563) 

ON.10 <- ontario.species %>% # This project is the biodiversity of Ontario - which should give us all of the unique taxa in ON
  filter(count <= 10) # Pull out taxa that have less than or equal to 10 in ON

observations %>% # filter the inventory records that match the taxa above
  filter(scientific_name %in% ON.10$taxon.name) %>%
  dplyr::select(scientific_name, quality_grade) %>%
  filter(quality_grade %in% c("research","needs_id"))
```

## Rare observations (<= 5 ON records)

```{r}
ON.5 <- ontario.species %>% # This project is the biodiversity of Ontario - which should give us all of the unique taxa in ON
  filter(count <= 5) # Pull out taxa that have less than or equal to 10 in ON

observations %>% # filter the inventory records that match the taxa above
  filter(scientific_name %in% ON.5$taxon.name) %>%
  dplyr::select(scientific_name, quality_grade) %>%
  filter(quality_grade %in% c("research","needs_id"))
```

## Rare observations (<= 3 ON records)

```{r}
ON.3 <- ontario.species %>% # This project is the biodiversity of Ontario - which should give us all of the unique taxa in ON
  filter(count <= 3) # Pull out taxa that have less than or equal to 10 in ON

observations %>% # filter the inventory records that match the taxa above
  filter(scientific_name %in% ON.3$taxon.name) %>%
  dplyr::select(scientific_name, quality_grade) %>%
  filter(quality_grade %in% c("research","needs_id"))
```

## Rare observations (<= 10 middlesex records)

```{r}
# Same thing but with middlesex county
middlesex.species <- iNat_sc(project_id = 29563) 

middlesex.10 <- middlesex.species %>% # This project is the biodiversity of Ontario - which should give us all of the unique taxa in ON
  filter(count <= 10) # Pull out taxa that have less than or equal to 10 in middlesex
  
observations %>% # filter the inventory records that match the taxa above
  filter(scientific_name %in% middlesex.10$taxon.name) %>%
  dplyr::select(scientific_name, quality_grade) %>%
  filter(quality_grade %in% c("research","needs_id"))
```

## Rare observations (<= 5 ON records)

```{r}
middlesex.5 <- middlesex.species %>% # This project is the biodiversity of Ontario - which should give us all of the unique taxa in ON
  filter(count <= 5) # Pull out taxa that have less than or equal to 10 in ON

observations %>% # filter the inventory records that match the taxa above
  filter(scientific_name %in% middlesex.5$taxon.name) %>%
  dplyr::select(scientific_name, quality_grade) %>%
  filter(quality_grade %in% c("research","needs_id"))
```

## Rare observations (<= 3 ON records)

```{r}
middlesex.3 <- middlesex.species %>% # This project is the biodiversity of Ontario - which should give us all of the unique taxa in ON
  filter(count <= 3) # Pull out taxa that have less than or equal to 10 in ON

observations %>% # filter the inventory records that match the taxa above
  filter(scientific_name %in% middlesex.3$taxon.name) %>%
  dplyr::select(scientific_name, quality_grade) %>%
  filter(quality_grade %in% c("research","needs_id"))
```

## Middlesex county first firsts

Too determine what the first firsts are for Middlesex, we need to download all the middlesex data (which is going to take a bit of time and too many records to do using 'get_inat_obs'). Luckily there aren't more that 200,000 observations, so we can just export the file on the website. 

If you want to repeat this, you'll need to download that file. 

```{r}
observations.middlesex <- read.csv("C:/Users/Admin/Documents/GitHub/Western-Biodiversity-Inventory_rinat/Data/observation_middlesex.csv")

# First firsts for middlesex county (within the timeframe of the survey)
first.firsts.middlesex <- observations.middlesex %>% 
  group_by(scientific_name) %>%
  slice_min(order_by = observed_on) %>%
  mutate(date = as_date(observed_on)) %>%
  arrange(desc(date)) %>%
  dplyr::select(scientific_name, date, user_name, id) %>%
  data.frame() %>%
  filter(date >= as_date("2022-04-01"),
         date <= as_date("2023-03-31"))
```

Once we have the first firsts for middlesex county - we just need to use those ID's to see which of them were seen within the inventory (see below).

```{r}
observations[observations$id %in% unique(first.firsts.middlesex$id),] %>%
  dplyr::select(scientific_name, quality_grade, id, observed_on) %>%
  filter(quality_grade %in% c("research","needs_id"))
```

